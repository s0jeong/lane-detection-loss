# utils/damage_calculator.py

import cv2
import numpy as np
from abc import ABC, abstractmethod
from typing import Dict, Any
from config import DAMAGE_CALCULATION_PARAMS, SAM_CLASSES, BRIGHT_CONTOUR_CLASSES, MAX_PIXEL_SAMPLE

class BaseDamageCalculator(ABC):
    """ì†ì‹¤ë¥  ê³„ì‚° ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    def __init__(self, params: Dict[str, Any] = None):
        self.params = params if params else DAMAGE_CALCULATION_PARAMS

    @abstractmethod
    def calculate(self, roi_image: np.ndarray, detected_mask: np.ndarray) -> float:
        """ROI ì´ë¯¸ì§€ì™€ ê²€ì¶œ ë§ˆìŠ¤í¬ë¡œ ì†ì‹¤ë¥  ê³„ì‚°"""
        pass

    def _calculate_by_color_similarity(self, roi_image: np.ndarray, detected_mask: np.ndarray) -> float:
        """ìƒ‰ìƒ ìœ ì‚¬ë„ ê¸°ë°˜ ì†ì‹¤ë¥  ê³„ì‚°"""
        # 1. ì…ë ¥ ì˜ˆì™¸ ì²˜ë¦¬
        if roi_image is None or roi_image.size == 0 or detected_mask is None or detected_mask.size == 0:
            return 1.0

        # --- ë™ì  ì¹¨ì‹ ì ìš© ---
        total_mask_area = np.count_nonzero(detected_mask)
        kernel = np.ones((3, 3), np.uint8)
        
        # (1) ë©´ì ì´ 2000 ë¯¸ë§Œ: 1ë²ˆë§Œ ê¹ìŒ
        if total_mask_area < 2000:
            eroded_mask = cv2.erode(detected_mask, kernel, iterations=1)
            
        # (2) ë©´ì ì´ 2000 ~ 3000: 2ë²ˆë§Œ ê¹ìŒ
        elif total_mask_area < 3000:
            eroded_mask = cv2.erode(detected_mask, kernel, iterations=2)
            
        # (3) ë©´ì ì´ 2000 ì´ìƒ: 3ë²ˆ ê¹ìŒ
        else:
            eroded_mask = cv2.erode(detected_mask, kernel, iterations=3)
        # ----------------------------------------------------

        # 2. ìœ íš¨ í”½ì…€ ì¶”ì¶œ
        all_masked_pixels_bgr = roi_image[eroded_mask > 0]
        total_pixels = len(all_masked_pixels_bgr)

        # [DEBUG] í‰ê·  í”½ì…€ ë°ê¸° í™•ì¸ìš© ì½”ë“œ
        if total_pixels > 0:
            # BGR í‰ê·  ê³„ì‚°
            mean_bgr = np.mean(all_masked_pixels_bgr, axis=0).astype(int)
            # ë°ê¸°(Grayscale) í‰ê·  ê³„ì‚° (ì´ ê°’ì´ brightness_thresholdë³´ë‹¤ ì»¤ì•¼ í•¨)
            gray_vals = cv2.cvtColor(all_masked_pixels_bgr.reshape(-1, 1, 3), cv2.COLOR_BGR2GRAY)
            mean_brightness = np.mean(gray_vals)
            
            # ë¡œê·¸ ì¶œë ¥: ë°ê¸°ê°€ 150 ë¯¸ë§Œì¸ ì–´ë‘ìš´ ê°ì²´ë§Œ ê²½ê³ ì²˜ëŸ¼ ì¶œë ¥í•´ì„œ í™•ì¸
            if mean_brightness < 150: 
                print(f"ğŸ” [Check] Dark Lane Detected! Area: {total_mask_area}, Mean Brightness: {mean_brightness:.1f}, Mean BGR: {mean_bgr}")
        
        # 3. ì•ˆì „ì¥ì¹˜ (Fallback)
        # ê¹ì•˜ë”ë‹ˆ í”½ì…€ì´ ë„ˆë¬´ ì ì–´ì¡Œë‹¤ë©´(20ê°œ ë¯¸ë§Œ), ë‹¤ì‹œ 1ë²ˆë§Œ ê¹ì€ ê±¸ë¡œ ì‹œë„
        if total_pixels < 20:
             if total_mask_area >= 1000:
                 eroded_mask = cv2.erode(detected_mask, kernel, iterations=2)
                 all_masked_pixels_bgr = roi_image[eroded_mask > 0]
                 total_pixels = len(all_masked_pixels_bgr)
             
             # ê·¸ë˜ë„ í”½ì…€ì´ ì—†ìœ¼ë©´ ì†ìƒ ì—†ìŒ(0.0)ìœ¼ë¡œ ì²˜ë¦¬
             if total_pixels < 20:
                 return 0.0 

        try:
            # 4. í”½ì…€ ìƒ˜í”Œë§ (ì†ë„ ìµœì í™”)
            if total_pixels > MAX_PIXEL_SAMPLE:
                indices = np.random.choice(total_pixels, MAX_PIXEL_SAMPLE, replace=False)
                sampled_pixels_bgr = all_masked_pixels_bgr[indices]
                total_pixels_in_sample = MAX_PIXEL_SAMPLE
            else:
                sampled_pixels_bgr = all_masked_pixels_bgr
                total_pixels_in_sample = total_pixels

            # 5. ê¸°ì¤€ ìƒ‰ìƒ(Dominant Color) ê²°ì • - Percentile ê¸°ë°˜
            gray_pixels = cv2.cvtColor(sampled_pixels_bgr.reshape(-1, 1, 3), cv2.COLOR_BGR2GRAY).flatten()

            # ìƒìœ„ 25% ë°ê¸° í”½ì…€ì„ ê¸°ì¤€ìœ¼ë¡œ dominant color ì„ íƒ
            percentile_threshold = np.percentile(gray_pixels, 75)  # 75 percentile = ìƒìœ„ 25%
            bright_pixels_bgr = sampled_pixels_bgr[gray_pixels > percentile_threshold]

            # ë°ì€ í”½ì…€ì´ ì¶©ë¶„íˆ ìˆìœ¼ë©´ ê·¸ ì¤‘ì—ì„œ ìµœë¹ˆ ìƒ‰ìƒ ì„ íƒ
            if len(bright_pixels_bgr) > 10:
                unique_colors, counts = np.unique(bright_pixels_bgr, axis=0, return_counts=True)
                dominant_color_bgr = unique_colors[counts.argmax()]
            else:
                # í´ë°±: ì „ì²´ í”½ì…€ ì¤‘ ìƒìœ„ 50% ë°ê¸°ì—ì„œ ì„ íƒ
                fallback_threshold = np.percentile(gray_pixels, 50)
                fallback_pixels_bgr = sampled_pixels_bgr[gray_pixels > fallback_threshold]
                if len(fallback_pixels_bgr) > 0:
                    unique_colors, counts = np.unique(fallback_pixels_bgr, axis=0, return_counts=True)
                    dominant_color_bgr = unique_colors[counts.argmax()]
                else:
                    # ìµœí›„ì˜ í´ë°±: ì „ì²´ í”½ì…€ ì¤‘ ìµœë¹ˆê°’
                    unique_colors, counts = np.unique(sampled_pixels_bgr, axis=0, return_counts=True)
                    dominant_color_bgr = unique_colors[counts.argmax()]
                    
            # 6. Delta E (ìƒ‰ìƒ ê±°ë¦¬) ê³„ì‚°
            dominant_color_lab = cv2.cvtColor(np.uint8([[dominant_color_bgr]]), cv2.COLOR_BGR2Lab)[0][0]
            all_masked_pixels_lab = cv2.cvtColor(sampled_pixels_bgr.reshape(-1, 1, 3).astype(np.uint8), cv2.COLOR_BGR2Lab).reshape(-1, 3)
            
            diff = all_masked_pixels_lab.astype(np.float32) - dominant_color_lab.astype(np.float32)
            delta_e = np.linalg.norm(diff, axis=1)

            # configì— ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 80.0 ì‚¬ìš©
            threshold = self.params.get('color_match_threshold', 80.0)
            good_pixels = np.sum(delta_e < threshold)
            
            damage_ratio = 1.0 - (good_pixels / total_pixels_in_sample)

            # 7. í¬ê¸° + í˜•íƒœ ê¸°ë°˜ ë³´ì •
            area_factor = min(1.0, total_mask_area / 2500.0)
            
            try:
                contours, _ = cv2.findContours(detected_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                if contours:
                    cnt = max(contours, key=cv2.contourArea)
                    rect = cv2.minAreaRect(cnt)
                    width, height = rect[1]
                    
                    if width > 0 and height > 0:
                        aspect_ratio = max(width, height) / min(width, height)
                        
                        # ê°€ëŠ˜ê³  ê¸´ ê°ì²´ì¼ìˆ˜ë¡ ì¶”ê°€ ë³´ì •
                        if aspect_ratio > 10:
                            shape_factor = 0.6
                        elif aspect_ratio > 5:
                            shape_factor = 0.8
                        else:
                            shape_factor = 1.0
                    else:
                        shape_factor = 1.0
                else:
                    shape_factor = 1.0
            except:
                shape_factor = 1.0
            
            scaling_factor = area_factor * shape_factor
            final_damage_ratio = damage_ratio * scaling_factor
            
            adjusted_ratio = self._apply_nonlinear_dampening(final_damage_ratio)
            return max(0.0, min(1.0, adjusted_ratio))

        except Exception as e:
            print(f"âš ï¸ Error in color calculation: {e}")
            return 1.0
    
    def _apply_nonlinear_dampening(self, raw_ratio: float, threshold: float = 0.03) -> float:
        """
        ì†ìƒë¥  ë¹„ì„ í˜• ë³´ì • í•¨ìˆ˜
        - 3% ì´í•˜: ê·¸ëŒ€ë¡œ ìœ ì§€
        - 3% ì´ìƒ: ì œê³±ê·¼ ìŠ¤ì¼€ì¼ë¡œ ì™„ë§Œí•˜ê²Œ ì••ì¶•
        
        Args:
            raw_ratio: ì›ë˜ ê³„ì‚°ëœ ì†ìƒë¥  (0.0~1.0)
            threshold: ë³´ì • ì‹œì‘ ê¸°ì¤€ê°’ (ê¸°ë³¸ 0.03 = 3%)
        
        Returns:
            ë³´ì •ëœ ì†ìƒë¥  (0.0~1.0)
        """
        if raw_ratio <= threshold:
            return raw_ratio  # 3% ì´í•˜ëŠ” ê·¸ëŒ€ë¡œ
        
        # 3% ì´ˆê³¼ë¶„ë§Œ ì••ì¶• (0.6 ì œê³±)
        excess = raw_ratio - threshold
        dampened_excess = excess ** 0.6
        
        return threshold + dampened_excess

class ColorBasedDamageCalculator(BaseDamageCalculator):
    """ì¼ë°˜ ìƒ‰ìƒ ê¸°ë°˜ ì†ì‹¤ë¥  ê³„ì‚°ê¸°"""
    def calculate(self, roi_image: np.ndarray, detected_mask: np.ndarray) -> float:
        return self._calculate_by_color_similarity(roi_image, detected_mask)

class EdgeBasedDamageCalculator(BaseDamageCalculator):
    """SAM/Edge ê¸°ë°˜ ì†ì‹¤ë¥  ê³„ì‚°ê¸°"""
    def calculate(self, roi_image: np.ndarray, detected_mask: np.ndarray) -> float:
        return self._calculate_by_color_similarity(roi_image, detected_mask)

class BrightnessDamageCalculator(BaseDamageCalculator):
    """ë°ê¸° ê¸°ë°˜ ì†ì‹¤ë¥  ê³„ì‚°ê¸°"""
    def calculate(self, roi_image: np.ndarray, detected_mask: np.ndarray) -> float:
        return self._calculate_by_color_similarity(roi_image, detected_mask)

def get_damage_calculator(class_name: str) -> BaseDamageCalculator:
    """í´ë˜ìŠ¤ë³„ ì ì ˆí•œ ì†ì‹¤ë¥  ê³„ì‚°ê¸° ë°˜í™˜"""
    if class_name in BRIGHT_CONTOUR_CLASSES:
        return BrightnessDamageCalculator()
    elif class_name in SAM_CLASSES:
        return EdgeBasedDamageCalculator()
    else:
        return ColorBasedDamageCalculator()